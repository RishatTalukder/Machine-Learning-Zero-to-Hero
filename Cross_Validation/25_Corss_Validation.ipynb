{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a15de11",
   "metadata": {},
   "source": [
    "# Cros Validation\n",
    "\n",
    "It's been almost 2 years since I've started learning about machine learning and it's internal structures and processes. One thing that still concerns me that no matter how careful you are with your data you can't always avoid the `bias and variance problem` and there aren't many creative solutions to it. But there is one thing that you can do and that is `Cross Validation`. Cross validation might not make bias-variance problem obsolete but it will definitely help you reduce bias-variance problem of a model. So, this article is about Cross Validation.\n",
    "\n",
    "As always, I'm `Md. Rishat Talukder` AKA `Itvaya`(Nobody knows me by that name), Let's get started.\n",
    "\n",
    "- [LinkedIn](https://www.linkedin.com/in/pro-programmer/)\n",
    "- [YouTube](http://www.youtube.com/@itvaya)\n",
    "- [gtihub](https://github.com/RishatTalukder/Machine-Learning-Zero-to-Hero)\n",
    "- [Gmail](talukderrishat2@gmail.com)\n",
    "- [discord](https://discord.gg/ZB495XggcF)\n",
    "\n",
    "# The Intuition of Bias-Variance Problem\n",
    "\n",
    "## The Intuition\n",
    "\n",
    "Let's say you are a student. You have an `exam coming` 1 week later. But you are `under-prepared` for the exam. \n",
    "\n",
    "So, you `study hard`. So, hard that by the exam time you cleared 80% of the syllabus. You are confident that you should at least get a moderate grade.\n",
    "\n",
    "And You did! You got 90%. Congrats!\n",
    "\n",
    "So, when you took the test you realised the questions from the 20% of the syllabus were not covered that much in the test and the teacher actually wrote almost all the questions from that 80% that you studied hard for.\n",
    "\n",
    "So, here's the question for you, _**Does this mean that you are secretly brilliant or were you just lucky? If the question from the rest of the 20% of the syllabus were covered in the test, do you thing you would have got a 100%?**_\n",
    "\n",
    "The answer is clearly, `No`. \n",
    "\n",
    "Now, imagine you took 5 more exams on the same syllabus. The questions are now more `scrambled` in the test. You average around 78%. \n",
    "\n",
    "This time the results looks trustworthy.\n",
    "\n",
    "Here's some crucial points:\n",
    "\n",
    "- After taking 5 exams you get a proper view of your performance, 1 exam is not enough to get a proper view of your performance.\n",
    "\n",
    "- You got lucky on the first test because the questions were not scrambled, on the later tests the questions were scrambled and you performed worse in some tests.\n",
    "\n",
    "Now, keep this intuition in mind because we are going to apply this in machine learning terms.\n",
    "\n",
    "## The Bias-Variance Problem\n",
    "\n",
    "Now, in the above example, the question was, _**Does this mean that you are secretly brilliant or were you just lucky?**_\n",
    "\n",
    "Let's get the point clear for the first exam:\n",
    "\n",
    "- You covered `80%` of the syllabus. Syllabus is the `dataset` and 80% is the `training set`.\n",
    "- You took the first test where almost all the questions were from that `80%` of the syllabus. The first test is the `training set`.\n",
    "- You performed `90%` in the first test. YOU are the `MODEL`.\n",
    "\n",
    "Now, let's rephrase the question:\n",
    "\n",
    "- You made a model that in trained on `80%` of the dataset and then tested it on `20%` of the dataset where most of the inputs are similar to the training set. \n",
    "\n",
    "- It leanred the 80% of the data patterns very well so, when faced with similar data it performed well. 90%.\n",
    "\n",
    "Which is amazing but this is a classic example of a `bias` in the model.\n",
    "\n",
    "That's is what we actually will see if we run the model on more diverse data multiple times.\n",
    "\n",
    "And if you have a dataset that has all the other 20% of the data patterns then the model will not perform as well as it did in the first test.\n",
    "\n",
    "So, one thing is clear, building and testing a model on a single configuration of data is not enough to get a proper view of the model performance.\n",
    "\n",
    "So, this is where `cross-validation` comes into play.\n",
    "\n",
    "# Cross Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
